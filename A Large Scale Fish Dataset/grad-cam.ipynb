{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "* **[1.專案的目的 📜](#1)**\n",
    "\n",
    "  - 對專案想法的簡單定義\n",
    "    \n",
    "\n",
    "* **[2.導入庫 📚](#2)**  \n",
    "\n",
    "   - 回顧完成專案的最重要庫 \n",
    "    \n",
    "\n",
    "* **[3.探索性數據分析 (EDA) 📊](#3)**  \n",
    "\n",
    "    - 通過數據及其在圖表中的表示了解信息\n",
    "\n",
    "    - 知道數據正常形式中不清晰的部分\n",
    "      \n",
    "\n",
    "* **[4.數據預處理 🔧](#4)**  \n",
    "    \n",
    "   - 數據切割 \n",
    "    \n",
    "   - 數據生成器 \n",
    "    \n",
    "\n",
    "* **[5.加載預訓練模型](#5)**  \n",
    "    \n",
    "    - 什麼是遷移學習\n",
    "    \n",
    "    - 回調函數\n",
    "    \n",
    "    - 訓練模型\n",
    "    \n",
    "    - 繪製模型\n",
    "    \n",
    "   \n",
    "* **[6.模型評估 📈](#6)**  \n",
    "    \n",
    "    - 分類報告\n",
    "    \n",
    "    - 混淆矩陣\n",
    "    \n",
    "   \n",
    "* **[7.Grad-Cam](#7)**\n",
    "    \n",
    "    - 簡單說明 CNN 如何看待\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://i.pinimg.com/originals/cd/5f/c4/cd5fc4478e62ab5ca0bfe091fdb58a50.gif\" alt=\"error\" width=\"400\" height=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"padding:10px;background-color:#8DA48E ;margin:0;color:white;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">專案的目的 📜</p>\n",
    "\n",
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "🔘 **問題**：魚類被認為是全球人口最重要的食物來源之一。隨著人口的增長和魚類消費的增加，對魚類的分類、識別和包裝需要花費大量的時間以及人力和物力成本。然而，隨著現代機械的出現，這一過程可以更輕鬆地完成，同時大幅降低成本。我們還可以保證持續運作，這意味著可以全天候工作，從而實現更好的魚類生產、分類和包裝。\n",
    "    \n",
    "🔘 **解決方案**：可以訓練一個模型來識別某些魚類，然後通過卷積神經網絡進行分類，並根據需要在許多與魚類相關的領域中使用它。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"padding:10px;background-color:#8DA48E ;margin:0;color:white;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">導入庫 📚</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #導入操作系統庫\n",
    "import glob as gb #導入文件操作庫\n",
    "import numpy as np #導入數據處理庫\n",
    "import pandas as pd #導入數據處理庫\n",
    "import seaborn as sns #導入視覺化庫\n",
    "from pathlib import Path #導入路徑庫\n",
    "import matplotlib.cm as cm #導入colormap\n",
    "import matplotlib.pyplot as plt #導入繪圖庫\n",
    "plt.style.use('Solarize_Light2') #設置繪圖風格\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #忽略警告\n",
    "\n",
    "import tensorflow as tf #導入tensorflow\n",
    "from tensorflow.keras.models import Sequential,Model #導入模型\n",
    "from tensorflow.keras.applications import MobileNetV2,VGG16 #導入預訓練模型\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,Dropout,BatchNormalization,Dense #導入層\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint #導入回調函數\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,array_to_img,img_to_array #導入圖像生成器\n",
    "\n",
    "from sklearn.model_selection import train_test_split #導入數據集劃分\n",
    "from sklearn.metrics import confusion_matrix,classification_report #導入混淆矩陣和分類報告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "# <p style=\"padding:10px;background-color:#8DA48E ;margin:0;color:white;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">探索性數據分析 (EDA) 📊 </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">準備所有數據路徑</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_path=r\"D:\\Learning_Python\\Exercises_Machine_Learning\\A Large Scale Fish Dataset\\archive\\Fish_Dataset\\Fish_Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">找出每個資料夾中的圖像數量</p>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = []  # 包含每個圖像的完整路徑\n",
    "for img_path in os.listdir(fish_path): \n",
    "    if img_path in ['Segmentation_example_script.m', 'README.txt', 'license.txt']:\n",
    "        continue  # 如果是這些特定的檔案，則跳過\n",
    "\n",
    "    all_data = gb.glob(pathname=fish_path + '/' + img_path + '/' + img_path + '/*.*')\n",
    "    print(' 在 {} 中找到 {} '.format(len(all_data), img_path))\n",
    "    all_path.extend(all_data)  # 將每個圖像的完整路徑加入到之前提到的 all_path 列表中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">創建圖像資料框</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建圖像的資料框\n",
    "images_df = pd.DataFrame({'Filepath': all_path})\n",
    "images_df['Label'] = images_df['Filepath'].apply(lambda x: x.split('/')[-2])  # 從路徑中提取標籤\n",
    "pd.options.display.max_colwidth = 200  # 設置顯示的最大列寬\n",
    "\n",
    "# 隨機打亂資料並重置索引\n",
    "images_df = images_df.sample(frac=1).reset_index(drop=True)\n",
    "images_df.head(5)  # 顯示前5行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">找出數據中每個標題的分佈情況</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定圖形大小為 15x5\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 繪製每個標籤的計數條形圖\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=images_df, x='Label')\n",
    "plt.xticks(rotation=60)\n",
    "\n",
    "# 繪製每個標籤的分佈餅圖\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(x=images_df['Label'].value_counts().values, \n",
    "        labels=images_df['Label'].value_counts().index, \n",
    "        autopct='%1.1f%%')\n",
    "\n",
    "# 設置整體標題\n",
    "plt.suptitle('數據中每個類別的分佈', size=20)\n",
    "plt.show()  # 顯示圖形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "**<p style=\"color:red\">觀察結果 📋</p>**    \n",
    "\n",
    "🔘 數據是平衡的，每個類別包含相等數量的圖像 **(1000)** 張圖像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">顯示數據集中20張圖片</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建一個 4x5 的圖形網格，大小為 15x7\n",
    "fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 7),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})  # 不顯示 x 和 y 軸刻度\n",
    "\n",
    "# 迴圈顯示圖片並設置標題為對應的標籤\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(images_df.Filepath[i]))  # 顯示圖片\n",
    "    ax.set_title(images_df.Label[i])  # 設置標題為標籤\n",
    "\n",
    "plt.tight_layout()  # 自動調整子圖間的間距\n",
    "plt.show()  # 顯示圖形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">數據切割</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將數據集切分為訓練集和測試集，測試集佔總數的 10%\n",
    "training_df, testing_df = train_test_split(images_df, test_size=0.1, shuffle=True, random_state=1)\n",
    "\n",
    "# 打印訓練數據和測試數據的維度\n",
    "print('訓練數據的維度:', training_df.shape)\n",
    "print('測試數據的維度:', testing_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">數據生成器</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建訓練數據生成器，使用 VGG16 的預處理函數，並進行 20% 的驗證數據劃分\n",
    "training_generator = ImageDataGenerator(\n",
    "    tf.keras.applications.vgg16.preprocess_input,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# 創建測試數據生成器，使用 VGG16 的預處理函數\n",
    "testing_generator = ImageDataGenerator(\n",
    "    tf.keras.applications.vgg16.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建訓練數據生成器\n",
    "training_images = training_generator.flow_from_dataframe(\n",
    "    dataframe=training_df,  # 使用訓練資料框\n",
    "    x_col='Filepath',  # 圖像路徑\n",
    "    y_col='Label',  # 圖像標籤\n",
    "    class_mode='categorical',  # 多類別分類\n",
    "    target_size=(224, 224),  # 圖像大小調整為 224x224\n",
    "    color_mode='rgb',  # 使用 RGB 色彩模式\n",
    "    batch_size=32,  # 批次大小為 32\n",
    "    shuffle=True,  # 隨機打亂數據\n",
    "    seed=42,  # 隨機種子\n",
    "    subset='training'  # 用於訓練子集\n",
    ")\n",
    "\n",
    "# 創建驗證數據生成器\n",
    "validation_images = training_generator.flow_from_dataframe(\n",
    "    dataframe=training_df,  # 使用訓練資料框\n",
    "    x_col='Filepath',  # 圖像路徑\n",
    "    y_col='Label',  # 圖像標籤\n",
    "    class_mode='categorical',  # 多類別分類\n",
    "    target_size=(224, 224),  # 圖像大小調整為 224x224\n",
    "    color_mode='rgb',  # 使用 RGB 色彩模式\n",
    "    batch_size=32,  # 批次大小為 32\n",
    "    shuffle=True,  # 隨機打亂數據\n",
    "    seed=42,  # 隨機種子\n",
    "    subset='validation'  # 用於驗證子集\n",
    ")\n",
    "\n",
    "# 創建測試數據生成器\n",
    "testing_images = testing_generator.flow_from_dataframe(\n",
    "    dataframe=testing_df,  # 使用測試資料框\n",
    "    x_col='Filepath',  # 圖像路徑\n",
    "    y_col='Label',  # 圖像標籤\n",
    "    class_mode='categorical',  # 多類別分類\n",
    "    target_size=(224, 224),  # 圖像大小調整為 224x224\n",
    "    color_mode='rgb',  # 使用 RGB 色彩模式\n",
    "    batch_size=32,  # 批次大小為 32\n",
    "    shuffle=False  # 不打亂數據（測試集通常不打亂）\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# <p style=\"padding:10px;background-color:#8DA48E ;margin:0;color:white;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">加載預訓練模型</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "**什麼是遷移學習**\n",
    "    \n",
    "🔘 遷移學習在卷積神經網絡 (CNN) 中是指使用在相似任務上已經訓練過的模型作為訓練新模型的起點，應用於不同的任務。\n",
    "\n",
    "**遷移學習的好處** \n",
    "    \n",
    "🔘 主要優勢是節省訓練時間，神經網絡在大多數情況下表現更好，而且不需要大量數據。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "🔘 **VGG-16**\n",
    "   是一個具有 16 層深度的卷積神經網絡。您可以加載在 ImageNet 數據庫中，基於超過一百萬張圖片訓練過的預訓練版本。\n",
    "\n",
    "🔘 預訓練的網絡可以將圖像分類為 1000 個物體類別，例如鍵盤、滑鼠、鉛筆和許多動物。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:827/1*UeAhoKM0kJfCPA03wt5H0A.png\" alt=\"error\" width=\"700\" height=\"600\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加載 VGG16 預訓練模型\n",
    "pretrained_model = VGG16(\n",
    "    input_shape=(224, 224, 3),  # 設置輸入圖像的形狀為 224x224，並具有 3 個通道 (RGB)\n",
    "    include_top=False,  # 不包含頂部的全連接層\n",
    "    weights='imagenet',  # 使用在 ImageNet 數據集上訓練的權重\n",
    "    pooling='avg'  # 使用全局平均池化來替代全連接層\n",
    ")\n",
    "\n",
    "# 凍結預訓練模型的權重，防止在訓練過程中被更新\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">回調函數</p>**\n",
    "\n",
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "🔘 **早停法 (Early Stopping)** 是深層神經網絡中的一種正則化技術，當參數更新不再對驗證集的結果帶來改進時，訓練將停止。\n",
    "\n",
    "🔘 **學習率衰減 (ReduceLROnPlateau)** 會在某個指標不再改進時減小學習率。這個回調函數會監控一個指標，如果在 '耐心' 設定的回合數內未看到改善，學習率就會被降低。\n",
    "\n",
    "🔘 **模型檢查點 (ModelCheckpoint)** 是用來定期保存 Keras 模型或模型權重的回調函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義早停回調函數\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 監控驗證集的損失\n",
    "    patience=3,  # 如果 3 個回合內驗證損失沒有改善則停止訓練\n",
    "    verbose=1,  # 顯示訓練過程的詳細信息\n",
    "    restore_best_weights=True  # 停止訓練時恢復最佳權重\n",
    ")\n",
    "\n",
    "# 定義學習率衰減回調函數\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 監控驗證集的損失\n",
    "    patience=2,  # 如果 2 個回合內損失未改善，則減小學習率\n",
    "    verbose=0,  # 不顯示詳細信息\n",
    "    factor=0.1  # 當條件滿足時，學習率縮小為原來的 0.1 倍\n",
    ")\n",
    "\n",
    "# 定義模型檢查點回調函數\n",
    "model_check_point = ModelCheckpoint(\n",
    "    monitor='val_accuracy',  # 監控驗證集的準確率\n",
    "    filepath='./bestmodel.h5',  # 保存最佳模型的文件路徑\n",
    "    save_best_only=True,  # 只保存最好的模型\n",
    "    verbose=True  # 顯示保存過程的詳細信息\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">訓練模型 </p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置訓練的回合數和批次大小\n",
    "epochs = 7\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義模型結構\n",
    "inputs = pretrained_model.input  # 使用預訓練模型的輸入層\n",
    "\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)  # 全連接層，128 個神經元，激活函數為 ReLU\n",
    "x = Dense(128, activation='relu')(x)  # 再添加一個 128 個神經元的全連接層\n",
    "x = Dropout(rate=0.3)(x)  # 隨機丟棄 30% 的神經元來防止過擬合\n",
    "x = BatchNormalization()(x)  # 批次正規化以加速訓練\n",
    "x = Dense(64, activation='relu')(x)  # 添加 64 個神經元的全連接層\n",
    "\n",
    "outputs = Dense(9, activation='softmax')(x)  # 輸出層，9 個分類，激活函數為 softmax\n",
    "\n",
    "# 創建模型\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# 編譯模型，設置優化器、損失函數和評估指標\n",
    "model.compile(\n",
    "    optimizer='adam',  # 使用 Adam 優化器\n",
    "    loss='categorical_crossentropy',  # 多類別交叉熵損失函數\n",
    "    metrics=['accuracy']  # 使用準確率作為評估指標\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "history = model.fit(\n",
    "    training_images,  # 訓練數據\n",
    "    validation_data=validation_images,  # 驗證數據\n",
    "    epochs=epochs,  # 訓練回合數\n",
    "    batch_size=batch_size,  # 每個批次的數據量\n",
    "    callbacks=[early_stopping, reduce_lr, model_check_point]  # 使用早停、學習率衰減和模型檢查點回調函數\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">模型摘要</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示模型摘要（模型結構）\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">繪製模型圖</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製模型結構圖\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">模型歷史資料框</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將訓練歷史記錄轉換為資料框\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df  # 顯示資料框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置圖形大小為 15x5\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 繪製準確率和驗證準確率的變化圖\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_df['accuracy'], label='accuracy', c='red')  # 繪製訓練準確率\n",
    "plt.plot(history_df['val_accuracy'], label='val_accuracy')  # 繪製驗證準確率\n",
    "plt.xlabel('回合數')  # 設置 x 軸標籤為回合數\n",
    "plt.ylabel('準確率')  # 設置 y 軸標籤為準確率\n",
    "plt.title('訓練準確率 VS 驗證準確率')  # 設置圖標題\n",
    "plt.legend()  # 顯示圖例\n",
    "\n",
    "# 繪製損失值和驗證損失值的變化圖\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_df['loss'], label='loss', c='red')  # 繪製訓練損失值\n",
    "plt.plot(history_df['val_loss'], label='val_loss')  # 繪製驗證損失值\n",
    "plt.title('訓練損失值 VS 驗證損失值')  # 設置圖標題\n",
    "plt.xlabel('回合數')  # 設置 x 軸標籤為回合數\n",
    "plt.ylabel('損失值')  # 設置 y 軸標籤為損失值\n",
    "plt.legend()  # 顯示圖例\n",
    "\n",
    "# 顯示所有繪製的圖\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">加載驗證準確率最高的模型</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加載最佳驗證準確率的模型\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('/kaggle/working/bestmodel.h5')  # 加載保存的最佳模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">在測試數據上評估模型</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在測試數據上評估模型\n",
    "Evaluation = model.evaluate(testing_images)\n",
    "\n",
    "# 輸出測試準確率和損失值\n",
    "print(\"測試準確率: {:.2f}%\".format(Evaluation[1] * 100))\n",
    "print(\"測試損失值: {:.5f}\".format(Evaluation[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">模型預測</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對測試數據進行預測\n",
    "prediction = model.predict(testing_images)\n",
    "# 使用 argmax 找出每個預測結果中的最大值索引（即預測的類別）\n",
    "prediction = np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看訓練數據中各類別的索引對應關係\n",
    "training_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得類別索引對應的標籤\n",
    "labels = (training_images.class_indices)\n",
    "# 將類別索引和標籤對調，以便從預測結果中還原標籤\n",
    "labels = dict((v, k) for k, v in labels.items())\n",
    "# 根據預測結果的索引還原為標籤\n",
    "prediction = [labels[k] for k in prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# <p style=\"padding:10px;background-color:#8DA48E ;margin:0;color:white;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">模型評估 📈 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲取測試數據中的真實標籤\n",
    "y_true = testing_df['Label'].values\n",
    "# 輸出分類報告，顯示模型的準確率、召回率和 F1 值等\n",
    "print(classification_report(y_true, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算混淆矩陣\n",
    "cm = confusion_matrix(y_true, prediction)\n",
    "# 設置圖形大小\n",
    "plt.figure(figsize=(15, 5))\n",
    "# 繪製混淆矩陣的熱圖\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', linewidths=0.5)\n",
    "# 設置 x 軸和 y 軸標籤\n",
    "plt.xlabel('預測標籤')  # 'predicted label'\n",
    "plt.ylabel('真實標籤')  # 'True label'\n",
    "# 設置圖標題\n",
    "plt.title('9 類別的混淆矩陣')\n",
    "# 顯示圖形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">準備預測值的資料框</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建一個複製的測試數據框並添加預測結果\n",
    "temp_df = testing_df.copy()\n",
    "temp_df['predicted'] = prediction  # 添加預測的標籤列\n",
    "\n",
    "# 將實際標籤與預測標籤進行比較，並標記是否相同\n",
    "temp_df.loc[temp_df['Label'] == temp_df['predicted'], 'Same'] = 'True'\n",
    "temp_df.loc[temp_df['Label'] != temp_df['predicted'], 'Same'] = 'False'\n",
    "\n",
    "# 重置索引\n",
    "temp_df = temp_df.reset_index(drop=True)\n",
    "temp_df.head()  # 顯示前 5 行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置圖形大小\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 繪製預測結果是否正確的柱狀圖\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(data=temp_df, x='Same')\n",
    "\n",
    "# 繪製預測結果是否正確的餅圖\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(x=temp_df['Same'].value_counts().values, \n",
    "        labels=temp_df['Same'].value_counts().index,\n",
    "        autopct='%1.1f%%', \n",
    "        explode=[0.1, 0.1])\n",
    "\n",
    "# 設置圖表的總標題\n",
    "plt.suptitle('預測圖像的模型評估', size=20)\n",
    "plt.show()  # 顯示圖表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義函數來顯示圖像\n",
    "def display_image(temp_df):\n",
    "    '''\n",
    "    輸入 : 數據框\n",
    "    \n",
    "    輸出 : 顯示數據框中的 8 張圖片\n",
    "    '''\n",
    "    # 創建一個 2x4 的圖形網格，大小為 15x7\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 7),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "    # 顯示圖片及其實際標籤和預測標籤\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(plt.imread(temp_df.Filepath.iloc[i]))\n",
    "        ax.set_title(f\"實際: {temp_df.Label.iloc[i]}\\n預測: {temp_df.predicted.iloc[i]}\") \n",
    "    plt.tight_layout()  # 自動調整子圖之間的間距\n",
    "    plt.show()  # 顯示圖像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">顯示預測正確的圖像</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示預測正確的圖像\n",
    "display_image(temp_df[temp_df['Same'] == 'True'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">顯示預測錯誤的圖像</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示預測錯誤的圖像\n",
    "display_image(temp_df[temp_df['Same'] == 'False'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "# <p style=\"padding:10px;background-color:#8DA48E ;margin:0;color:white;font-family:newtimeroman;font-size:100%;text-align:center;border-radius: 15px 50px;overflow:hidden;font-weight:500\">Grad-Cam </p>\n",
    "\n",
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "🔘 返回梯度加權類別激活映射 **(Grad-CAM)**\n",
    "\n",
    "🔘 使用流入 CNN 最後一層卷積層的梯度信息來理解每個神經元對所關注決策的貢獻。\n",
    "\n",
    "🔘 **Grad-CAM** 方法用於提取深層神經網絡的特徵圖，隨後使用注意力機制來提取高層次的注意力圖。注意力圖突出顯示了圖像中對目標類別重要的區域，可以視為深層神經網絡的視覺解釋。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_conv_layer='block5_conv3' # 您可以通過模型摘要來得知這一點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "# 定義函數來獲取圖像的數組格式\n",
    "def get_img_array(img_path, size):\n",
    "    img = load_img(img_path, target_size=size)  # 加載圖像並調整大小\n",
    "    array = img_to_array(img)  # 將圖像轉換為數組\n",
    "    # 增加一個維度，將數組轉換為 \"批次\" 格式\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "# 定義函數來生成 Grad-CAM 熱圖\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # 創建一個模型，將輸入圖像映射到最後一層卷積層的激活值以及模型的預測輸出\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # 計算輸入圖像的預測類別對應的梯度，相對於最後一層卷積層的激活值\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])  # 如果沒有指定預測類別，則使用預測概率最大的類別\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # 計算輸出神經元（預測的類別）相對於最後一層卷積層輸出特徵圖的梯度\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # 將每個特徵圖通道的梯度取平均，得到一個向量\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # 將梯度加權應用到最後一層卷積層的輸出，生成熱圖\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # 將熱圖的值規範化到 0 到 1 之間，便於視覺化\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# 定義函數來保存並顯示 Grad-CAM 熱圖\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # 加載原始圖像\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # 將熱圖重新調整到 0-255 的範圍\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # 使用 jet 色彩映射來將熱圖進行著色\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # 提取 RGB 色彩值\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # 創建一個帶有 RGB 色彩熱圖的圖像\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # 將熱圖疊加到原始圖像上\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = array_to_img(superimposed_img)\n",
    "\n",
    "    # 保存疊加後的圖像\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # 顯示 Grad-CAM\n",
    "#     display(Image(cam_path))\n",
    "    \n",
    "    return cam_path\n",
    "\n",
    "# 預處理和解碼 VGG16 預測結果的函數\n",
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "decode_predictions = tf.keras.applications.vgg16.decode_predictions\n",
    "\n",
    "# 最後一層卷積層的名稱，來自模型摘要\n",
    "last_conv_layer_name = \"block5_conv3\"\n",
    "img_size = (224, 224)\n",
    "\n",
    "# 移除最後一層的 softmax 激活函數\n",
    "model.layers[-1].activation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_heatmap_image(df):\n",
    "    '''\n",
    "    輸入 : 數據框\n",
    "    \n",
    "    輸出 : 顯示數據框中的 8 張 Grad-CAM 圖像\n",
    "    '''\n",
    "    \n",
    "    # 創建一個 2x4 的圖形網格，大小為 15x10\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(15, 10),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "    # 遍歷每個圖像，生成 Grad-CAM 熱圖並顯示\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img_path = df.Filepath.iloc[i]  # 獲取圖像路徑\n",
    "        img_array = preprocess_input(get_img_array(img_path, size=img_size))  # 預處理圖像數據\n",
    "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)  # 生成 Grad-CAM 熱圖\n",
    "        cam_path = save_and_display_gradcam(img_path, heatmap)  # 保存並顯示 Grad-CAM 圖像\n",
    "        ax.imshow(plt.imread(cam_path))  # 顯示 Grad-CAM 圖像\n",
    "        ax.set_title(f\"實際: {df.Label.iloc[i]}\\n預測: {df.predicted.iloc[i]}\")  # 設置圖像標題為實際與預測標籤\n",
    "    plt.tight_layout()  # 自動調整子圖間距\n",
    "    plt.show()  # 顯示圖像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">顯示預測正確圖像的熱圖</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示預測正確圖像的 Grad-CAM 熱圖\n",
    "display_heatmap_image(temp_df[temp_df['Same'] == 'True'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "**<p style=\"color:red\">觀察結果 📋</p>**    \n",
    "\n",
    "🔘 卷積神經網絡確定了每種魚類最重要的區分特徵\n",
    "\n",
    "🔘 陰影部分顯示了卷積神經網絡進行分類決策的依據"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:#6D4318\">顯示預測錯誤圖像的熱圖</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示預測錯誤圖像的 Grad-CAM 熱圖\n",
    "display_heatmap_image(temp_df[temp_df['Same'] == 'False'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "**<p style=\"color:red\">觀察結果 📋</p>**    \n",
    "\n",
    "🔘 卷積神經網絡無法清晰地識別部分區域，這可能是由於兩種不同魚類的大小或顏色相似，再加上圖像模糊所致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'border : 3px solid lightblue; background-color:#ABB9AB;padding:10px'>\n",
    "\n",
    "# [感謝觀看到最後。如果您從這個筆記本中受益，請支持我點贊 ❤️](https://www.kaggle.com/code/mohamedwasef/acc-98-fish-classification-with-grad-cam/comments)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
